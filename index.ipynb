{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Typically we don't know statistics about a population itself; the only way to know these for sure would be to survey the entirety of the population which is typically impractical. For example, to know the true salary mean of individuals in the United States, we would have to survey each and every individual.\n",
    "\n",
    "In lieu of being able to know the true underlying population statistics, we estimate them. Point estimates are estimates of population parameters based on sample data. For instance, if we wanted to know the average age of registered voters in the U.S., we could take a survey of registered voters and then use the average age of the respondents as a point estimate of the average age of the population as a whole. \n",
    "\n",
    "The average of a sample is known as the sample mean. Sampling distribution can be thought of as relative frequency distribution with a large number of samples. A relative frequency distribution tends to approach the sampling distribution as number of samples increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "\n",
    "* Calculate and interpret standard error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Terminologies: \n",
    "\n",
    "In order to learn the **population mean**, we dont measure the whole population. Instead, we take a random sample and use **sample mean, ( x_bar or $\\bar{x}$ )** to estimate population mean **( mu or μ )**. The sample mean is usually not exactly the same as the population mean and depends upon the values of samples chosen, however the population mean remains fixed. While using **sample mean** to estimate population mean, we come across **sampling error**, which directly relates to the **standard deviation** of a sampling statistic (e.g. mean values). This difference can be caused by many factors including poor survey design, biased sampling methods and the randomness inherent to drawing a sample from a population.\n",
    "\n",
    "Let's learn about these concepts through an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Pumpkin Weights**\n",
    ">The population is the weight of six pumpkins (in pounds) displayed in a carnival \"guess the weight\" game booth. You are asked to guess the average weight of the six pumpkins by picking two pumpkins at a time randomly untill all pumpkins have been used.\n",
    "\n",
    "| Pumpkin | Weight (in pounds) |\n",
    "|---------|--------------------|\n",
    "| A       |       19           |\n",
    "| B       |       14           |\n",
    "| C       |       15           |\n",
    "| D       |       9            |\n",
    "| E       |       10           |\n",
    "| F       |       17           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "\n",
    "Lets calculate the population mean first, which we calculate as:\n",
    "\n",
    "**μ = sum of all elements / N** (where N is population size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two lists with pumpkin name and respective pumpkin weights. COmbine the lists to create a pumpkin directory with name as keys and weights as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 19, 'B': 14, 'C': 15, 'D': 9, 'E': 10, 'F': 17}\n"
     ]
    }
   ],
   "source": [
    "# Create two lists with pumpkin names and weights\n",
    "\n",
    "pumpkins = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "weights = [19, 14, 15, 9, 10, 17]\n",
    "\n",
    "# Combine both lists to create a dictionary\n",
    "\n",
    "pumpkin_dict = dict(zip(pumpkins, weights))\n",
    "\n",
    "print (pumpkin_dict)\n",
    "\n",
    "#{'A': 19, 'B': 14, 'C': 15, 'D': 9, 'E': 10, 'F': 17}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try to calculate the mean of the pumpkin population and also visualise the weight distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the population mean from pumpkin_dict\n",
    "\n",
    "def calculate_mu(x):\n",
    "\n",
    "    # Use the formula for mu given above\n",
    "    d = sum(x.values()) / len(x.values())\n",
    "\n",
    "    return (d)   \n",
    "\n",
    "mu = calculate_mu(pumpkin_dict)\n",
    "mu\n",
    "\n",
    "# 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was pretty a straightforward exercise. Let's use the data we have so far to visualise the weights of individual pumpkins and mean weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (2,) and (6,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b619d79ee9a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pumpkin Weights'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpumpkins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpumpkins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (6,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a bar graph showing weights of pumpkins and highlight the mean weight\n",
    "plt.style.use('ggplot')\n",
    "plt.xlabel('Pumpkin Names')\n",
    "plt.ylabel('Pumpkin Weights')\n",
    "plt.bar(pumpkins, weights)\n",
    "plt.plot(, [mu for i in range(len(pumpkins))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see only one pumpkin has weight which is equal to mean weight (B:14). Let's try to simulate the random sampling process as stated below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 : Calculate mean of samples\n",
    "\n",
    "From the `pumpkin_dict`, we can now obtain the sampling distributions of the sample mean for a given sample size. We shall do this while sampling without replacement (to reflect the idea that one can have two pumpkins at a given time, and will be taken out of population once used). \n",
    "\n",
    "Let's also try to make the code more flexible to allow sampling any number of pumpkins from the population, to study the effect of sample size on sample mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve this, first we need to identify all the possible combinations that can be observed by choosing 2 pumpkins from the population, following the game rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify a sample size n \n",
    "n = 2 \n",
    "\n",
    "# Use itertools.combinations() to generate and print a list of combinations\n",
    "combs = None\n",
    "\n",
    "\n",
    "# Using 2 samples, we can see 15 possible combinations as below:\n",
    "# [('A', 'B'), ('A', 'C'), ('A', 'D'), ('A', 'E'), ('A', 'F'), ('B', 'C'), ('B', 'D'), \n",
    "#  ('B', 'E'), ('B', 'F'), ('C', 'D'), ('C', 'E'), ('C', 'F'), ('D', 'E'), ('D', 'F'), \n",
    "#  ('E', 'F')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. We can now generate any number of combinations from the population (try changing the value of n above). Next step in the process is to calculate the mean of all possible combinations and study weather these means differes from the population mean, and whether sample size has any effect towards estimating population mean. \n",
    "\n",
    "Lets write a function which would include the code for generating combinations as above and also identifying mean for each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_means(sample_size, data):\n",
    "\n",
    "    \"\"\"\n",
    "    This function takes in population data as a dictionary along with a chosen sample size \n",
    "    to generate all possible combinations of given sample size. \n",
    "    The function calculates the mean of each sample and returns:\n",
    "    a) a list of all combinations ( as tuples ) \n",
    "    b) a list of means for all sample\n",
    "    \"\"\"\n",
    "\n",
    "    n = sample_size\n",
    "\n",
    "    # Calculate the mean of population\n",
    "    mu = None\n",
    "    #print (\"Mean of population is:\", mu)\n",
    "\n",
    "    # Generate all possible combinations using given sample size\n",
    "    combs = None\n",
    "\n",
    "    # Calculate the mean weight (x_bar) for all the combinations (samples) using the given data\n",
    "    x_bar_list = []\n",
    "\n",
    "    # Calculate sample mean for all combinations and append to x_bar_list\n",
    " \n",
    "\n",
    "    return combs, x_bar_list\n",
    "\n",
    "n = 2 #Sample size\n",
    "\n",
    "combs, means = sample_means(n, pumpkin_dict)\n",
    "\n",
    "# Print the sample combinations with their means\n",
    "\n",
    "\n",
    "\n",
    "# Using 2 samples, we can see 15 possible combinations as below:\n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "# ('A', 'B') 16.5\n",
    "# ('A', 'C') 17.0\n",
    "# ('A', 'D') 14.0\n",
    "# ('A', 'E') 14.5\n",
    "# ('A', 'F') 18.0\n",
    "# ('B', 'C') 14.5\n",
    "# ('B', 'D') 11.5\n",
    "# ('B', 'E') 12.0\n",
    "# ('B', 'F') 15.5\n",
    "# ('C', 'D') 12.0\n",
    "# ('C', 'E') 12.5\n",
    "# ('C', 'F') 16.0\n",
    "# ('D', 'E') 9.5\n",
    "# ('D', 'F') 13.0\n",
    "# ('E', 'F') 13.5\n",
    "# The mean of all sample means mu_x_hat is: 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, even though each sample may give you an answer involving some error, the expected value is right at the target: exactly the population mean. In other words, \n",
    ">If one does the experiment over and over again, the overall average of the sample mean is exactly the population mean.\n",
    "\n",
    "In the output above, we can see that some mean values i.e. 14.5, 12, are being repeated in the combinations. We can develop a frequency table identify the probability of seeing different mean value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability(means):\n",
    "    '''\n",
    "    Input: a list of means (x_hats)\n",
    "    Output: a list of probablitity of each mean value\n",
    "    '''\n",
    "    #Calculate the frequency of each mean value\n",
    "    freq = None\n",
    "\n",
    "    prob = []\n",
    "\n",
    "    # Calculate and append fequency of each mean value in the prob list. \n",
    "\n",
    "    return prob\n",
    "    \n",
    "probs = calculate_probability(means)\n",
    "\n",
    "# Print combinations with sample means and probability of each mean value\n",
    "\n",
    "\n",
    "# ('A', 'B') 16.5 1/15\n",
    "# ('A', 'C') 17.0 1/15\n",
    "# ('A', 'D') 14.0 1/15\n",
    "# ('A', 'E') 14.5 2/15\n",
    "# ('A', 'F') 18.0 1/15\n",
    "# ('B', 'C') 14.5 2/15\n",
    "# ('B', 'D') 11.5 1/15\n",
    "# ('B', 'E') 12.0 2/15\n",
    "# ('B', 'F') 15.5 1/15\n",
    "# ('C', 'D') 12.0 2/15\n",
    "# ('C', 'E') 12.5 1/15\n",
    "# ('C', 'F') 16.0 1/15\n",
    "# ('D', 'E') 9.5 1/15\n",
    "# ('D', 'F') 13.0 1/15\n",
    "# ('E', 'F') 13.5 1/15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the chance that the sample mean is exactly the population mean (i.e. 14) is only 1 in 15 (row 3), very small. It may also happen that the sample mean can never be the same value as the population mean. \n",
    "\n",
    " The difference between sample mean and population mean is known as known as **Sampling Error**.  \n",
    "\n",
    ">When using the sample mean to estimate the population mean, some possible error will be involved since random sample mean is also random.\n",
    "\n",
    "## Sample size and sampling error: \n",
    "\n",
    "Sample means cluster more closely around the population mean as the sample size increases. Thus, possible sampling error decreases as sample size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat above exercise while increasing the sample size from 2 to 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "# Use above functions to generate combinations as samples with means and calculate the probability of seeing\n",
    "# each mean value  with sample size = 5.\n",
    "\n",
    "# Using 5 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "# 1 ('A', 'B', 'C', 'D', 'E') 13.4 1/6\n",
    "# 2 ('A', 'B', 'C', 'D', 'F') 14.8 1/6\n",
    "# 3 ('A', 'B', 'C', 'E', 'F') 15.0 1/6\n",
    "# 4 ('A', 'B', 'D', 'E', 'F') 13.8 1/6\n",
    "# 5 ('A', 'C', 'D', 'E', 'F') 14.0 1/6\n",
    "# 6 ('B', 'C', 'D', 'E', 'F') 13.0 1/6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that using sample mean to estimate population mean involves sampling error. Sample means do not fully agree with population mean. The mean of sample means, however, is still 14. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fully appreciate the impact of sample size on estimating population mean, let's try to visualize sample means and how the spread of values change when changing sample size. \n",
    "\n",
    "In a loop, run the above experiment with sample sizes ranging from 1 to 5 and measure and visualise the spread of values around population mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a for loop to execute above code for sample size 1 to 5 and visualise the spread of sample \n",
    "# means\n",
    "\n",
    "\n",
    "\n",
    "# Using 1 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 2 samples with a population of size, we can see 15 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 3 samples with a population of size, we can see 20 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 4 samples with a population of size, we can see 15 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0\n",
    "\n",
    "# Using 5 samples with a population of size, we can see 6 possible combinations \n",
    "# The mean of all sample means mu_x_hat is: 14.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here can see that with increasing sample size, the **spread** of sample means is reducing and sample mean values tend to come closer to population mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the standard error\n",
    "\n",
    "### So what is standard error ?\n",
    "\n",
    "The standard error(SE) is very similar to standard deviation. Both are measures of spread. The higher the number, the more spread out your data is. To put it simply, the two terms are essentially equal — but there is one important difference. While the standard error uses statistics (sample data) standard deviations use parameters (population data). We achieve this dividing the standard deviation by the square root of\n",
    "the sample size.\n",
    "The calculation for the standard error of the sample mean is:\n",
    "\n",
    "## $$ \\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}} \\approx \\frac{s}{\\sqrt{n}}$$\n",
    "\n",
    "Here, $\\sigma$ is the population standard deviation (which we will approximate with the sample standard deviation) and $n$ is the sample size.\n",
    "\n",
    "Lets run above block of code again and calculate standard error according to chosen sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create empty lists for storing sample means, combinations and standard error for each iteration\n",
    "means_list = []\n",
    "combs_list = []\n",
    "err_list = []\n",
    "# Create a for loop with changing sample sizes\n",
    "    \n",
    "    # Calculate combinations, means as earlier, append to relevant lists\n",
    "\n",
    "    \n",
    "\n",
    "    # Calculate and append the standard error by dividing sample means with square root of sample size\n",
    "\n",
    "    \n",
    "\n",
    "    # Visualize sample spread and standard error values for each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, even though each sample may give you an answer involving some error, the expected value is right at the target: exactly the population mean. In other words, if one does the experiment over and over again, the overall average of the sample mean is exactly the population mean. If the sample size is increased, the standard error is reduced. \n",
    "\n",
    "According to **Central Limit Theorem**, for a large sample size, x_hat is approximately normally distributed, regardless of the distribution of the population one samples from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab we saw how sampling statistics relate to population statistics. In order to estimate a population parameter (i.e. mean) with a high level of accuracy, We must reduce the spread or the sample error which is simply the standard deviation of the samples from the sample mean. The size of samples must be set carefully in order to avoid excessive values for standard error to gain a high level of confidence in our population estimates. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
